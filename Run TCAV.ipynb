{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running TCAV\n",
    "\n",
    "\n",
    "This notebook walks you through things you need to run TCAV. In high level, you need:\n",
    "\n",
    "1. **example images in each folder**\n",
    " * images for each concept\n",
    " * images for the class/labels of interest\n",
    " * random images that will be negative examples when learning CAVs (images that probably don't belong to any concepts)\n",
    "2. **model wrapper**: an instance of  ModelWrapper abstract class (in model.py). This tells TCAV class (tcav.py) how to communicate with your model (e.g., getting internal tensors)\n",
    "3. **act_generator**: an instance of ActivationGeneratorInterface that tells TCAV class how to load example data and how to get activations from the model\n",
    "\n",
    "\n",
    "\n",
    "## Requirements\n",
    "\n",
    "    Install sklearn and PIL before running below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cav as cav\n",
    "import model  as model\n",
    "import tcav as tcav\n",
    "import utils as utils\n",
    "import utils_plot as utils_plot # utils_plot requires matplotlib\n",
    "import os \n",
    "import activation_generator as act_gen\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Store concept and target class images to local folders\n",
    "\n",
    "and tell TCAV where they are.\n",
    "\n",
    "**source_dir**: where images of concepts, target class and random images (negative samples when learning CAVs) live. Each should be a sub-folder within this directory.\n",
    "\n",
    "Note that random image directories can be in any name. In this example, we are using `random500_0`, `random500_1`,.. for an arbitrary reason. \n",
    "\n",
    "\n",
    "You need roughly 50-200 images per concept and target class (10-20 pictures also tend to work, but 200 is pretty safe).\n",
    "\n",
    "\n",
    "**cav_dir**: directory to store CAVs (`None` if you don't want to store)\n",
    "\n",
    "**target, concept**: names of the target class (that you want to investigate) and concepts (strings) - these are folder names in source_dir\n",
    "\n",
    "**bottlenecks**: list of bottleneck names (intermediate layers in your model) that you want to use for TCAV. These names are defined in the model wrapper below.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the name of your model wrapper (InceptionV3 and GoogleNet are provided in model.py)\n",
    "model_to_run = 'GoogleNet'  \n",
    "user = 'beenkim'\n",
    "# the name of the parent directory that results are stored (only if you want to cache)\n",
    "project_name = 'tcav_class_test'\n",
    "working_dir = \"/tmp/\" + user + '/' + project_name\n",
    "# where activations are stored (only if your act_gen_wrapper does so)\n",
    "activation_dir =  working_dir+ '/activations/'\n",
    "# where CAVs are stored. \n",
    "# You can say None if you don't wish to store any.\n",
    "cav_dir = working_dir + '/cavs/'\n",
    "# where the images live. \n",
    "source_dir = \"/Users/beenkim/image_net_subsets/\"\n",
    "bottlenecks = [ 'mixed4d']  # @param \n",
    "      \n",
    "utils.make_dir_if_not_exists(activation_dir)\n",
    "utils.make_dir_if_not_exists(working_dir)\n",
    "utils.make_dir_if_not_exists(cav_dir)\n",
    "\n",
    "# this is a regularizer penalty parameter for linear classifier to get CAVs. \n",
    "alphas = [0.1]   \n",
    "\n",
    "target = 'zebra'  \n",
    "concepts = [\"dotted\",\"striped\",\"zigzagged\"]   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Write your model wrapper\n",
    "\n",
    "Next step is to tell TCAV how to communicate with your model. See `model.GoolgeNetWrapper_public ` for details.\n",
    "\n",
    "You can define a subclass of ModelWrapper abstract class to do this. Let me walk you thru what each function does (tho they are pretty self-explanatory).  This wrapper includes a lot of the functions that you already have, for example, `get_prediction`.\n",
    "\n",
    "### 1. Tensors from the graph: bottleneck tensors and ends\n",
    "First, store your bottleneck tensors in `self.bottlenecks_tensors` as a dictionary. You only need bottlenecks that you are interested in running TCAV with. Similarly, fill in `self.ends` dictionary with `input`, `logit` and `prediction` tensors.\n",
    "\n",
    "### 2. Define loss\n",
    "Get your loss tensor, and assigned it to `self.loss`. This is what TCAV uses to take directional derivatives. \n",
    "\n",
    "While doing so, you would also want to set \n",
    "```python\n",
    "self.y_input \n",
    "```\n",
    "this simply is a tensorflow place holder for the target index in the logit layer (e.g., 0 index for a dog, 1 for a cat).\n",
    "For multi-class classification, typically something like this works:\n",
    "\n",
    "```python\n",
    "self.y_input = tf.placeholder(tf.int64, shape=[None])\n",
    "```\n",
    "\n",
    "For example, for a multiclass classifier, something like below would work. \n",
    "\n",
    "```python\n",
    "    # Construct gradient ops.\n",
    "    with g.as_default():\n",
    "      self.y_input = tf.placeholder(tf.int64, shape=[None])\n",
    "\n",
    "      self.pred = tf.expand_dims(self.ends['prediction'][0], 0)\n",
    "\n",
    "      self.loss = tf.reduce_mean(\n",
    "          tf.nn.softmax_cross_entropy_with_logits(\n",
    "              labels=tf.one_hot(self.y_input, len(self.labels)),\n",
    "              logits=self.pred))\n",
    "    self._make_gradient_tensors()\n",
    "```\n",
    "\n",
    "### 3. Call _make_gradient_tensors in __init__() of your wrapper\n",
    "```python\n",
    "_make_gradient_tensors()  \n",
    "```\n",
    "does what you expect - given the loss and bottleneck tensors defined above, it adds gradient tensors.\n",
    "\n",
    "### 4. Fill in labels, image shapes and a model name.\n",
    "Get the mapping from labels (strings) to indice in the logit layer (int) in a dictionary format.\n",
    "\n",
    "```python\n",
    "def id_to_label(self, idx)\n",
    "def label_to_id(self, label)\n",
    "```\n",
    "\n",
    "Set your input image shape at  `self.image_shape`\n",
    "\n",
    "\n",
    "Set your model name to `self.model_name`\n",
    "\n",
    "You are done with writing the model wrapper! I wrote two model wrapers, InceptionV3 and Googlenet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**sess**: a tensorflow session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = utils.create_session()\n",
    "\n",
    "# GRAPH_PATH is where the trained model is stored.\n",
    "GRAPH_PATH =  '/Users/beenkim/trained_models/google_net_inception_v1/tensorflow_inception_graph.pb'\n",
    "# LABEL_PATH is where the labels are stored. Each line contains one class, and they are ordered with respect to their index in \n",
    "# the logit layer. (yes, id_to_label function in the model wrapper reads from this file.)\n",
    "# For example, imagenet_comp_graph_label_strings.txt looks like:\n",
    "# dummy                                                                                      \n",
    "# kit fox\n",
    "# English setter\n",
    "# Siberian husky ...\n",
    "\n",
    "LABEL_PATH = '/Users/beenkim/trained_models/google_net_inception_v1/imagenet_comp_graph_label_strings.txt'\n",
    "    \n",
    "mymodel = model.GoolgeNetWrapper_public(sess,\n",
    "                                        GRAPH_PATH,\n",
    "                                        LABEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Implement a class that returns activations (maybe with caching!)\n",
    "\n",
    "Lastly, you will implement a class of the ActivationGenerationInterface which TCAV uses to load example data for a given concept or target, call into your model wrapper and return activations. I pulled out this logic outside of mymodel because this step often takes the longest. By making it modular, you can cache your activations and/or parallelize your computations, as I have done in `ActivationGeneratorBase.process_and_load_activations` in `activation_generator.py`.\n",
    "\n",
    "\n",
    "The `process_and_load_activations` method of the activation generator must return a dictionary of activations that has concept or target name as  a first key, and the bottleneck name as a second key. So something like:\n",
    "\n",
    "```python\n",
    "{concept1: {bottleneck1: [[0.2, 0.1, ....]]},\n",
    "concept2: {bottleneck1: [[0.1, 0.02, ....]]},\n",
    "target1: {bottleneck1: [[0.02, 0.99, ....]]}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_generator = act_gen.ImageActivationGenerator(mymodel, source_dir, activation_dir, max_examples=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You are ready to run TCAV!\n",
    "\n",
    "Let's do it.\n",
    "\n",
    "**num_random_exp**: number of experiments to confirm meaningful concept direction. TCAV will search for this many folders named `random500_0`, `random500_1`, etc. You can alternatively set the `random_concepts` keyword to be a list of folders of random concepts. Run at least 10-20 for meaningful tests. \n",
    "\n",
    "**random_counterpart**: as well as the above, you can optionally supply a single folder with random images as the \"positive set\" for statistical testing. Reduces computation time at the cost of less reliable random TCAV scores. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity(0)\n",
    "\n",
    "mytcav = tcav.TCAV(sess,\n",
    "                   target,\n",
    "                   concepts,\n",
    "                   bottlenecks,\n",
    "                   act_generator,\n",
    "                   alphas,\n",
    "                   cav_dir=cav_dir,\n",
    "                   num_random_exp=10)\n",
    "\n",
    "results = mytcav.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils_plot.plot_results(results, num_random_exp=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
